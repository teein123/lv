import streamlit as st
import akshare as ak
import pandas as pd
import numpy as np
import datetime
import traceback

# ==========================================
# é¡µé¢é…ç½®
# ==========================================
st.set_page_config(
    page_title="AIç¼ è®ºæŠ•å–‚ç³»ç»Ÿ v6.0",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==========================================
# 1. æ ¸å¿ƒç®—æ³•ï¼šé€šè¾¾ä¿¡ç‰ˆ MACD (é€’å½’è®¡ç®—)
# ==========================================
def calculate_macd(df):
    """
    æ¨¡æ‹Ÿé€šè¾¾ä¿¡/åŒèŠ±é¡ºçš„MACDè®¡ç®—å…¬å¼
    """
    df = df.copy()
    close = df['close'].values
    
    def calc_ema_recursive(series, span):
        alpha = 2 / (span + 1)
        ema = np.zeros_like(series)
        ema[0] = series[0] 
        for i in range(1, len(series)):
            ema[i] = alpha * series[i] + (1 - alpha) * ema[i-1]
        return ema

    df['ema12'] = calc_ema_recursive(close, 12)
    df['ema26'] = calc_ema_recursive(close, 26)
    df['dif'] = df['ema12'] - df['ema26']
    df['dea'] = calc_ema_recursive(df['dif'].values, 9)
    df['macd'] = (df['dif'] - df['dea']) * 2
    return df

# ==========================================
# 2. åŸºç¡€åŠ›åº¦è®¡ç®— (åŒå‘çº¢ç»¿æŸ±é€»è¾‘)
# ==========================================
def get_segment_metrics_by_date(raw_df, start_date, end_date, direction):
    mask = (raw_df['date'] >= start_date) & (raw_df['date'] <= end_date)
    segment_df = raw_df.loc[mask].copy()
    if segment_df.empty: return 0.0, 0.0, 0.0

    # ã€è§„åˆ™ã€‘ï¼šä¸Šæ¶¨åªç®—çº¢æŸ±ï¼Œä¸‹è·Œåªç®—ç»¿æŸ±
    if direction == 'å‘ä¸Š':
        # åªåŠ çº¢æŸ±å­ (macd > 0)
        macd_area = segment_df[segment_df['macd'] > 0]['macd'].sum()
        idx_price = segment_df['high'].idxmax()
    else:
        # åªåŠ ç»¿æŸ±å­ (macd < 0)ï¼Œå–ç»å¯¹å€¼
        macd_area = abs(segment_df[segment_df['macd'] < 0]['macd'].sum())
        idx_price = segment_df['low'].idxmin()
    
    peak_dif = segment_df.loc[idx_price, 'dif']
    avg_vol = segment_df['volume'].mean() / 10000 
    
    return round(macd_area, 4), round(peak_dif, 4), round(avg_vol, 2)

# ==========================================
# 3. ç¼ è®ºKçº¿åŒ…å«å¤„ç† (è§†è§‰å…¼å®¹ç‰ˆ)
# ==========================================
def preprocess_inclusion(df):
    if len(df) < 2: return df
    raw_data = df.to_dict('records')
    # åˆå§‹åŒ– real_date
    for d in raw_data: 
        if 'real_date' not in d: d['real_date'] = d['date']

    processed = [raw_data[0]]
    direction = 1 
    if raw_data[1]['close'] < raw_data[0]['close']: direction = -1

    for i in range(1, len(raw_data)):
        cur = raw_data[i]
        last = processed[-1]
        
        is_cur_inside = (cur['high'] <= last['high'] and cur['low'] >= last['low'])
        is_last_inside = (cur['high'] >= last['high'] and cur['low'] <= last['low'])
        
        if is_cur_inside or is_last_inside:
            last['volume'] = float(last['volume']) + float(cur['volume'])
            last['date'] = cur['date'] # é€»è¾‘æ—¶é—´æ¨ç§»
            last['close'] = cur['close']
            
            # è§†è§‰ä¿æŠ¤é€»è¾‘
            last_amp = (last['high'] - last['low']) / last['low'] if last['low'] > 0 else 0
            if last_amp > 0.015: 
                last['high'] = max(last['high'], cur['high'])
                last['low'] = min(last['low'], cur['low']) 
            else:
                if direction == 1:
                    last['high'] = max(last['high'], cur['high'])
                    last['low'] = max(last['low'], cur['low'])
                else:
                    last['high'] = min(last['high'], cur['high'])
                    last['low'] = min(last['low'], cur['low'])
            
            # ã€é‡è¦ã€‘æ›´æ–°çœŸå®æ—¶é—´ (real_date)
            # å¦‚æœæ–°Kçº¿åˆ›é€ äº†æ–°çš„æå€¼ï¼Œåˆ™æ›´æ–°çœŸå®æ—¶é—´ï¼›å¦åˆ™ä¿ç•™åŸæå€¼æ—¶é—´
            if direction == 1 and cur['high'] == last['high']: last['real_date'] = cur['real_date']
            elif direction == -1 and cur['low'] == last['low']: last['real_date'] = cur['real_date']
        else:
            if cur['high'] > last['high'] and cur['low'] > last['low']: direction = 1
            elif cur['high'] < last['high'] and cur['low'] < last['low']: direction = -1
            processed.append(cur)
            
    return pd.DataFrame(processed)

# ==========================================
# 4. ç¼ è®ºåˆ†ç¬”æ ¸å¿ƒ (å·²ä¿®å¤MACDè®¡ç®—èŒƒå›´)
# ==========================================
def calculate_chanlun_structure(df):
    if len(df) < 10: return [] 

    k_df = preprocess_inclusion(df)
    k_df = k_df.reset_index(drop=True)
    if len(k_df) < 5: return [] 

    k_df['type'] = 0 
    for i in range(1, len(k_df)-1):
        prev, curr, next_ = k_df.iloc[i-1], k_df.iloc[i], k_df.iloc[i+1]
        if curr['high'] > prev['high'] and curr['high'] > next_['high'] and curr['low'] > prev['low'] and curr['low'] > next_['low']:
            k_df.loc[i, 'type'] = 1 
        elif curr['low'] < prev['low'] and curr['low'] < next_['low'] and curr['high'] < prev['high'] and curr['high'] < next_['high']:
            k_df.loc[i, 'type'] = -1 
        
        if k_df.loc[i, 'type'] == 0:
            if curr['high'] >= prev['high'] and curr['high'] >= next_['high'] and curr['high'] > max(prev['high'], next_['high']):
                 k_df.loc[i, 'type'] = 1
            elif curr['low'] <= prev['low'] and curr['low'] <= next_['low'] and curr['low'] < min(prev['low'], next_['low']):
                 k_df.loc[i, 'type'] = -1

    fractals = k_df[k_df['type'] != 0].copy()
    if len(fractals) < 2: return []
    
    stack = [fractals.iloc[0]]
    for i in range(1, len(fractals)):
        curr = fractals.iloc[i]
        last = stack[-1]
        
        if curr['type'] == last['type']:
            if curr['type'] == 1 and curr['high'] > last['high']:
                stack.pop(); stack.append(curr)
            elif curr['type'] == -1 and curr['low'] < last['low']:
                stack.pop(); stack.append(curr)
            continue
            
        if curr.name - last.name >= 4:
            is_valid_space = False
            if last['type'] == 1 and curr['type'] == -1 and curr['low'] < last['low']: is_valid_space = True
            if last['type'] == -1 and curr['type'] == 1 and curr['high'] > last['high']: is_valid_space = True
            if (curr.name - last.name >= 9): is_valid_space = True
            if is_valid_space: stack.append(curr)
            
    bi_list = []
    if len(stack) < 2: return []
    
    for i in range(1, len(stack)):
        start_node = stack[i-1]
        end_node = stack[i]
        bi_dir = 'å‘ä¸Š' if start_node['type'] == -1 else 'å‘ä¸‹'
        
        # ã€æ ¸å¿ƒä¿®å¤ã€‘ï¼šä½¿ç”¨ real_date (çœŸå®æå€¼æ—¶é—´) æˆªæ­¢ï¼Œç¡®ä¿é¢ç§¯ä¸è¢«å¤šç®—
        a, p, v = get_segment_metrics_by_date(df, start_node['real_date'], end_node['real_date'], bi_dir)
        
        bi_list.append({
            'start_date': start_node['date'], 'end_date': end_node['date'],
            'display_start_date': start_node['real_date'], 'display_end_date': end_node['real_date'],
            'start_price': float(start_node['low']) if start_node['type'] == -1 else float(start_node['high']),
            'end_price': float(end_node['low']) if end_node['type'] == -1 else float(end_node['high']),
            'direction': bi_dir, 'macd_area': a, 'peak_dif': p, 'avg_vol': v
        })
            
    return bi_list

# ==========================================
# 5. æ™ºèƒ½é‡èƒ½åˆ†æ (åŒå‘çº¢ç»¿æŸ±é€»è¾‘)
# ==========================================
def analyze_unformed_segment(df, last_bi):
    last_end_date = last_bi['end_date']
    unformed_df = df[df['date'] > last_end_date].copy()
    if len(unformed_df) == 0: return None
    
    last_dir = last_bi['direction']
    last_end_price = last_bi['end_price']
    
    current_dir = 'å‘ä¸‹' if last_dir == 'å‘ä¸Š' else 'å‘ä¸Š'
    status_note = "ã€æ­£å¸¸å›è°ƒã€‘"
    
    if last_dir == 'å‘ä¸Š':
        if unformed_df['high'].max() > last_end_price:
            current_dir = 'å‘ä¸Š'; status_note = "ã€å¼ºåŠ¿å»¶ç»­ã€‘"
    else: 
        if unformed_df['low'].min() < last_end_price:
            current_dir = 'å‘ä¸‹'; status_note = "ã€ä¸‹è·Œä¸­ç»§ã€‘"

    physical_count = len(unformed_df)
    logical_df = preprocess_inclusion(unformed_df)
    logical_count = len(logical_df)
    current_avg_vol = unformed_df['volume'].mean() / 10000

    # åŠ›åº¦è®¡ç®—ï¼šåŒå‘é€»è¾‘
    if current_dir == 'å‘ä¸Š':
        macd_area = unformed_df[unformed_df['macd'] > 0]['macd'].sum()
        peak_dif = unformed_df.loc[unformed_df['high'].idxmax(), 'dif']
    else:
        macd_area = abs(unformed_df[unformed_df['macd'] < 0]['macd'].sum())
        peak_dif = unformed_df.loc[unformed_df['low'].idxmin(), 'dif']

    return {
        'count': physical_count, 'logical_count': logical_count,
        'high': unformed_df['high'].max(), 'low': unformed_df['low'].min(), 'close': unformed_df.iloc[-1]['close'],
        'macd_area': round(macd_area, 4), 'peak_dif': round(peak_dif, 4),
        'avg_vol': round(current_avg_vol, 2), 
        'current_dir': current_dir,
        'status': status_note
    }

# ==========================================
# 6. æ•°æ®è·å–
# ==========================================
@st.cache_data(ttl=3600) 
def get_stock_data(code, freq='d'):
    """ ä»ä¸œæ–¹è´¢å¯Œè·å–ä¼˜è´¨æ•°æ® (æœ€è¿‘2å¹´) """
    pure_code = code.split('.')[-1]
    try:
        start_date = (datetime.date.today() - datetime.timedelta(days=730)).strftime('%Y%m%d')
        end_date = datetime.date.today().strftime('%Y%m%d')

        if freq == 'd':
            df = ak.stock_zh_a_hist(symbol=pure_code, period="daily", start_date=start_date, end_date=end_date, adjust="qfq")
            if not df.empty:
                df = df.rename(columns={'æ—¥æœŸ':'date','å¼€ç›˜':'open','æœ€é«˜':'high','æœ€ä½':'low','æ”¶ç›˜':'close','æˆäº¤é‡':'volume'})
        else:
            df = ak.stock_zh_a_hist_min_em(symbol=pure_code, period='30', adjust='qfq')
            if not df.empty:
                df = df.rename(columns={'æ—¶é—´':'date','å¼€ç›˜':'open','æœ€é«˜':'high','æœ€ä½':'low','æ”¶ç›˜':'close','æˆäº¤é‡':'volume'})
            
        if not df.empty:
            df['date'] = pd.to_datetime(df['date'])
            cols = ['open','high','low','close','volume']
            for c in cols: df[c] = pd.to_numeric(df[c])
            df = df.sort_values('date').reset_index(drop=True)
        return df
    except Exception as e:
        st.error(f"æ•°æ®è·å–å¼‚å¸¸: {e}")
        return pd.DataFrame()

# ==========================================
# Main App Logic
# ==========================================
def main():
    st.title("ğŸ§™â€â™‚ï¸ AIç¼ è®ºæŠ•å–‚ç³»ç»Ÿ v6.0 (æœ€ç»ˆä¿®å¤ç‰ˆ)")
    st.markdown("""
    **ç‰ˆæœ¬ç‰¹æ€§**: 
    1. **MACDç²¾åº¦ä¿®æ­£**ï¼šé¢ç§¯è®¡ç®—ç²¾ç¡®å¯¹é½Kçº¿çœŸå®æå€¼æ—¶é—´ï¼Œæ¶ˆé™¤åŒ…å«å¤„ç†å¸¦æ¥çš„è¯¯å·®ã€‚
    2. **å®æˆ˜åŠ›åº¦**ï¼šå‘ä¸Šç¬”åªç®—çº¢æŸ±ï¼Œå‘ä¸‹ç¬”åªç®—ç»¿æŸ±ã€‚
    3. **è§†è§‰å…¼å®¹**ï¼šä¿æŠ¤å¤§é˜´å¤§é˜³çº¿ä¸è¢«ç®—æ³•åæ²¡ã€‚
    """)
    
    with st.sidebar:
        st.header("å‚æ•°è®¾ç½®")
        code = st.text_input("è¾“å…¥è‚¡ç¥¨ä»£ç ", value="600885", help="æ”¯æŒAè‚¡ä»£ç ï¼Œå¦‚ 600519")
        run_btn = st.button("å¼€å§‹åˆ†æ", type="primary")

    if run_btn and code:
        try:
            with st.spinner(f'æ­£åœ¨æ·±å…¥åˆ†æ {code} ...'):
                df_d = get_stock_data(code, 'd')
                if df_d.empty:
                    st.warning("æœªè·å–åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥ä»£ç ã€‚")
                    return
                df_d = calculate_macd(df_d)
                
                # æ•°æ®éªŒé’æœº
                with st.expander("ğŸ” æ•°æ®éªŒé’æœº (ç‚¹å‡»å±•å¼€)"):
                    st.markdown("è¯·æ ¸å¯¹æœ€å3æ—¥çš„MACDæ•°æ®ï¼š")
                    cols_to_show = ['date', 'close', 'dif', 'dea', 'macd']
                    st.dataframe(df_d.tail(3)[cols_to_show].style.format({
                        'close': '{:.2f}', 'dif': '{:.3f}', 'dea': '{:.3f}', 'macd': '{:.3f}'
                    }))
                
                # è®¡ç®—ç»“æ„
                bi_d = calculate_chanlun_structure(df_d)
                
                df_30 = get_stock_data(code, '30')
                bi_30 = []
                if not df_30.empty:
                    df_30 = calculate_macd(df_30)
                    bi_30 = calculate_chanlun_structure(df_30)
                
                # ç”Ÿæˆæç¤ºè¯
                prompt = f"""
åŸºäºã€ŠAIç¼ è®ºåˆ†æç³»ç»Ÿæœ€é«˜æŒ‡ä»¤ v6.0ã€‹ï¼Œæ•°æ®æºé€šè¾¾ä¿¡å¯¹é½ï¼ŒMACDé¢ç§¯è®¡ç®—å·²ä¿®æ­£ä¸ºçœŸå®æ—¶é—´çª—å£ã€‚
**æ ¸å¿ƒè§„åˆ™ï¼š**
1. **åŠ›åº¦è®¡ç®—**ï¼šé‡‡ç”¨ã€åŒå‘æŸ±ä½“ç´¯è®¡ã€‘ã€‚
   - å‘ä¸Šç¬”ï¼šä»…ç´¯åŠ MACDçº¢æŸ±é¢ç§¯ã€‚
   - å‘ä¸‹ç¬”ï¼šä»…ç´¯åŠ MACDç»¿æŸ±é¢ç§¯ã€‚
2. **ç”»ç¬”é€»è¾‘**ï¼šè§†è§‰å…¼å®¹æ¨¡å¼ï¼ˆé€»è¾‘Kçº¿è§†è§’ï¼‰ã€‚

ã€åˆ†ææ ‡çš„ã€‘ï¼š{code}

=== çº§åˆ«ä¸€ï¼šæ—¥çº¿ (å®šæ–¹å‘) ===
æ•°æ®èŒƒå›´ï¼š{df_d.iloc[0]['date'].date()} è‡³ {df_d.iloc[-1]['date'].date()}
ã€æ—¥çº¿æ ‡å‡†ç¬”åºåˆ— (æœ€å13ç¬”)ã€‘
"""
                d_num = min(13, len(bi_d))
                if d_num > 0:
                    for i, bi in enumerate(bi_d[-d_num:]):
                        s_str = bi['display_start_date'].strftime('%Y-%m-%d')
                        e_str = bi['display_end_date'].strftime('%Y-%m-%d')
                        bi_idx = len(bi_d) - (d_num - 1) + i
                        area_desc = "çº¢æŸ±é¢ç§¯" if bi['direction'] == 'å‘ä¸Š' else "ç»¿æŸ±é¢ç§¯"
                        prompt += f"- ç¬”{bi_idx} [{bi['direction']}]: {s_str} -> {e_str} | ä»·:{bi['start_price']}->{bi['end_price']} | {area_desc}:{bi['macd_area']} | DIFæå€¼:{bi['peak_dif']} | å‡é‡:{bi['avg_vol']}ä¸‡\n"
                
                if bi_d:
                    unf = analyze_unformed_segment(df_d, bi_d[-1])
                    if unf:
                        area_type = "çº¢æŸ±" if unf['current_dir'] == 'å‘ä¸Š' else "ç»¿æŸ±"
                        prompt += f"""
ã€æ—¥çº¿å½“ä¸‹çŠ¶æ€ (æœªæˆç¬”æ®µ)ã€‘
- è¿è¡Œ: {unf['count']}å¤© (é€»è¾‘Kçº¿: {unf['logical_count']}æ ¹)
- æ–¹å‘: {unf['current_dir']} ({unf['status']})
- æå€¼: é«˜{unf['high']} / ä½{unf['low']} / æ”¶{unf['close']}
- åŠ›åº¦: MACD{area_type}é¢ç§¯ {unf['macd_area']}, DIFæå€¼ {unf['peak_dif']}
"""

                prompt += "\n=== çº§åˆ«äºŒï¼š30åˆ†é’Ÿ (æ‰¾ä¹°å–ç‚¹) ===\n"
                if bi_30:
                    d30_num = min(13, len(bi_30))
                    prompt += f"ã€30åˆ†é’Ÿæ ‡å‡†ç¬”åºåˆ— (æœ€å{d30_num}ç¬”)ã€‘\n"
                    for i, bi in enumerate(bi_30[-d30_num:]):
                        s_str = bi['display_start_date'].strftime('%m-%d %H:%M')
                        e_str = bi['display_end_date'].strftime('%m-%d %H:%M')
                        bi_idx = len(bi_30) - (d30_num - 1) + i
                        area_desc = "çº¢ç§¯" if bi['direction'] == 'å‘ä¸Š' else "ç»¿ç§¯"
                        prompt += f"- ç¬”{bi_idx} [{bi['direction']}]: {s_str} -> {e_str} | ä»·:{bi['start_price']}->{bi['end_price']} | {area_desc}:{bi['macd_area']} | DIFæå€¼:{bi['peak_dif']}\n"
                    
                    unf30 = analyze_unformed_segment(df_30, bi_30[-1])
                    if unf30:
                        prompt += f"""
ã€30åˆ†é’Ÿå½“ä¸‹çŠ¶æ€ã€‘
- æ–¹å‘: {unf30['current_dir']}
- ç»“æ„: ç‰©ç†{unf30['count']}æ ¹ / é€»è¾‘{unf30['logical_count']}æ ¹
- åŠ›åº¦: MACD{("çº¢ç§¯" if unf30['current_dir'] == 'å‘ä¸Š' else "ç»¿ç§¯")} {unf30['macd_area']}, DIFæå€¼ {unf30['peak_dif']}
"""
                else: prompt += "ï¼ˆæ•°æ®ä¸è¶³ï¼‰\n"
                
                prompt += """
ã€ä½ çš„ä»»åŠ¡ã€‘
1. **èƒŒé©°åˆ¤æ–­**ï¼šåŸºäºä¿®æ­£åçš„MACDé¢ç§¯ï¼ˆçœŸå®æ—¶é—´çª—å£ï¼‰åˆ¤æ–­è¶‹åŠ¿è¡°ç«­ã€‚
2. **ä¸­æ¢ç²¾ç®—**ï¼šä¸¥æ ¼è¾“å‡º ZG/ZD åŒºé—´ã€‚
3. **ç­–ç•¥**ï¼šç»“åˆ30åˆ†é’Ÿä¹°å–ç‚¹æç¤ºã€‚
"""
                st.success("åˆ†æå®Œæˆï¼")
                st.code(prompt, language='text')
                
        except Exception:
            st.error("å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥ä»£ç ")
            st.error(traceback.format_exc())

if __name__ == "__main__":
    main()
